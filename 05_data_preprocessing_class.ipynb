{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandasql import sqldf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 Class\n",
    "class preprocessing_data(object):\n",
    "    \"\"\"\n",
    "    도매, 소매, 수입수출, 도매경락, 주산지 데이터 전처리용 class\n",
    "    중간결과물 저장 check parameter을 통해 지정, 중간결과물 저장 없이 사용은 check = 0\n",
    "    \"\"\"\n",
    "    def __init__(self,dir):\n",
    "        \"\"\"\n",
    "        전체 데이터에서 해당하는 domae,imexport,pummok,somae,weather 별 분리\n",
    "        \"\"\"\n",
    "        self.data_list = glob(dir)\n",
    "        self.domae = []\n",
    "        self.imexport = []\n",
    "        self.pummok = []\n",
    "        self.somae = []\n",
    "        self.weather = []\n",
    "\n",
    "        for i in self.data_list:\n",
    "            if 'dome' in i:\n",
    "                self.domae.append(i)\n",
    "            if 'imexport' in i:\n",
    "                self.imexport.append(i)\n",
    "            if 'pummok' in i:\n",
    "                self.pummok.append(i)\n",
    "            if 'some' in i:\n",
    "                self.somae.append(i)\n",
    "            if 'weather' in i:\n",
    "                self.weather.append(i)\n",
    "\n",
    "\n",
    "    def add_pummock(self,check=0):\n",
    "\n",
    "        \"\"\"\n",
    "        check = 중간 산출물을 저장하고 싶다면 check 을 0 이외의 숫자로\n",
    "        pummock의 데이터를 가져와 '해당일자_전체거래물량', '하위가격 평균가', '상위가격 평균가', '하위가격 거래물량', '상위가격 거래물량' 의 파생변수를 생성하는 단계\n",
    "        \"\"\"\n",
    "\n",
    "        for num in tqdm(self.pummok):\n",
    "            df = pd.read_csv(num)  # pummock의 csv 읽어오기\n",
    "        \n",
    "            name = num.split('/')[-1] # 전체 정제한 데이터를 담을 변수 이름\n",
    "            # 해당 날짜에 거래가 있는지 확인하고 있는 날짜의 경우 'nan'인 행을 제거\n",
    "            filtered_df = df.groupby(\"datadate\").apply(lambda x: x.dropna() if not (x.iloc[:, 1:].isnull().all().all()) else x)\n",
    "            filtered_df.reset_index(drop=True, inplace=True)\n",
    "            # 결측값을 0으로 채움\n",
    "            filtered_df.fillna(0, inplace=True)\n",
    "\n",
    "            # 총거래량, 총거래대금, 경락단가 변수 df 추가\n",
    "            filtered_df['총거래량'] = filtered_df['거래단량']*filtered_df['거래량']\n",
    "            filtered_df['총거래대금'] = filtered_df['경락가']*filtered_df['거래량']\n",
    "            filtered_df['경락단가'] = filtered_df['총거래대금']//filtered_df['총거래량']\n",
    "\n",
    "            # 날짜별로 총 거래량, 총 거래대금을 합산\n",
    "            grouped_totals = filtered_df.groupby('datadate').agg({'총거래량': 'sum', '총거래대금': 'sum'})\n",
    "\n",
    "            # 날짜별로 평균가격 계산 (총 거래대금 / 총 거래량)\n",
    "            grouped_totals['평균가격'] = grouped_totals['총거래대금'] // grouped_totals['총거래량']\n",
    "\n",
    "            # 각 행(i.e. 날짜, 시장명)에 매칭되는 평균가격 조회 및 추가하기\n",
    "            filtered_df['해당일자_평균가격'] = filtered_df['datadate'].map(grouped_totals['평균가격'])\n",
    "\n",
    "            df = filtered_df\n",
    "\n",
    "            sep2 = sqldf(f\"select *, sum(총거래량) as '해당일자_전체거래물량' from df group by datadate\")\n",
    "            # sql 문법을 이용해 '해당일자_전체거래물량' 계산\n",
    "\n",
    "            height_set = []\n",
    "            low_set = []\n",
    "            height_volume_set = []\n",
    "            low_volume_set = []\n",
    "\n",
    "            for i in sep2['datadate']:\n",
    "                print(i)\n",
    "                \"\"\"\n",
    "                sep2는 group by를 통해 각 일자가 합쳐진 상태 예를 들어 '201703' 이 5개 이렇게 있을때 sep2는 group 시켜서 '해당일자_전체거래물량'을 계산\n",
    "                이후 sep2 기준 20170101 and 20220630 사이의 날짜들에 해당하는 각 '201703' 마다 '해당일자_전체평균가격' 보다 큰지 아니면 작은지 판단\n",
    "                위 과정을 통해 '하위가격 평균가', '상위가격 평균가', '하위가격 거래물량', '상위가격 거래물량' 변수 생성\n",
    "                \"\"\"\n",
    "                new_list = df.loc[[d for d, x in enumerate(df['datadate']) if x == i]]\n",
    "                set_price = sep2.loc[list(sep2['datadate']).index(i)]['해당일자_평균가격']\n",
    "\n",
    "                sum_he_as = sum(new_list['총거래대금'].iloc[n] for n, z in enumerate(new_list['경락단가']) if z >= set_price)\n",
    "                sum_he_vo = sum(new_list['총거래량'].iloc[n] for n, z in enumerate(new_list['경락단가']) if z >= set_price)\n",
    "\n",
    "                sum_lo_as = sum(new_list['총거래대금'].iloc[n] for n, z in enumerate(new_list['경락단가']) if z < set_price)\n",
    "                sum_lo_vo = sum(new_list['총거래량'].iloc[n] for n, z in enumerate(new_list['경락단가']) if z < set_price)\n",
    "\n",
    "                if sum_lo_vo != 0:\n",
    "                    low_set.append(sum_lo_as // sum_lo_vo)\n",
    "                    low_volume_set.append(sum_lo_vo)\n",
    "                else:\n",
    "                    low_set.append(np.nan)\n",
    "                    low_volume_set.append(np.nan)\n",
    "\n",
    "                if sum_he_vo != 0:\n",
    "                    height_set.append(sum_he_as // sum_he_vo)\n",
    "                    height_volume_set.append(sum_he_vo)\n",
    "                else:\n",
    "                    height_set.append(np.nan)\n",
    "                    height_volume_set.append(np.nan)\n",
    "\n",
    "            sep2['하위가격 평균가(원)'] = low_set\n",
    "            sep2['상위가격 평균가(원)'] = height_set\n",
    "\n",
    "            sep2['하위가격 거래물량(kg)'] = low_volume_set\n",
    "            sep2['상위가격 거래물량(kg)'] = height_volume_set\n",
    "\n",
    "            globals()[f'df_{name.split(\"_\")[1].split(\".\")[0]}'] = sep2.copy()\n",
    "\n",
    "            # 중간 산출물 저장\n",
    "            if check != 0:\n",
    "                if os.path.exists(f'../AI/DATA/data') == False:\n",
    "                    os.mkdir(f'../AI/DATA/data')\n",
    "\n",
    "                if os.path.exists(f'../AI/DATA/data/pummok') == False:\n",
    "                    os.mkdir(f'../AI/DATA/data/pummok')\n",
    "\n",
    "                sep2.to_csv(f'../AI/DATA/data/pummok/{name}', index=False)\n",
    "\n",
    "    def add_dosomae(self, option=1, check=0):\n",
    "\n",
    "        \"\"\"\n",
    "        check = 중간 산출물을 저장하고 싶다면 check 을 0 이외의 숫자로\n",
    "        domae, somae 데이터를 가져와서 정제하는 단계\n",
    "        option parameter을 통한 도매, 소매 선택\n",
    "        \"\"\"\n",
    "        if option == 1:\n",
    "            df = self.domae\n",
    "            text = '도매'\n",
    "        else:\n",
    "            df = self.somae\n",
    "            text = '소매'\n",
    "\n",
    "        for i in tqdm(df):\n",
    "            test = pd.read_csv(i)\n",
    "            test.rename(columns={'가격등록일자': 'datadate'}, inplace=True)\n",
    "            name = i.split('/')[-1]\n",
    "            print(name)\n",
    "\n",
    "            test.fillna(0, inplace=True)\n",
    "            sep = test.loc[(test['산물등급명'] == '상품') | (test['산물등급명'] == 'S과')]  # 모든 상품에 대해서 수행하지 않고 GRAD_NM이 '상품', 'S과' 만 해당하는 품목 가져옴\n",
    "            sep = sep[['datadate', '산물등급명', f'{text}출하단위크기', '품목가격',]]\n",
    "            if text == '도매':\n",
    "                sep['가격'] = sep['품목가격']//sep[f'{text}출하단위크기']\n",
    "            else:\n",
    "                sep['가격'] = sep['품목가격']//sep[f'{text}출하단위크기']\n",
    "\n",
    "            # sep.rename(columns={\"품목가격\": \"가격\"}, inplace=True)\n",
    "\n",
    "            sep2 = sqldf(\n",
    "                    f\"select datadate, max(가격) as '일자별_{text}가격_최대(원)', avg(가격) as '일자별_{text}가격_평균(원)', min(가격) as '일자별_{text}가격_최소(원)' from sep group by datadate\")\n",
    "\n",
    "            globals()[f'df_{name.split(\"_\")[1].split(\".\")[0]}'] = globals()[f'df_{name.split(\"_\")[1].split(\".\")[0]}'].merge(sep2, how='left')\n",
    "\n",
    "            # 중간 산출물 저장\n",
    "            if check != 0:\n",
    "                if os.path.exists(f'../AI/DATA/data') == False:\n",
    "                    os.mkdir(f'../AI/DATA/data')\n",
    "\n",
    "                if os.path.exists(f'../AI/DATA/data/{text}') == False:\n",
    "                    os.mkdir(f'../AI/DATA/data/{text}')\n",
    "\n",
    "                sep2.to_csv(f'../AI/DATA/data/{text}/{name}', index=False)\n",
    "\n",
    "    def add_imexport(self,check=0):\n",
    "        \"\"\"\n",
    "        check = 중간 산출물을 저장하고 싶다면 check 을 0 이외의 숫자로\n",
    "        imexport 데이터 관련 정제, imexport 데이터는 월별 수입수출 데이터임으로 해당 월에 같은 값을 넣어주고 없는 것에는 np.nan\n",
    "        해당 품목에 대한 imexport 데이터가 없는 경우 np.nan으로 대체, 모든 품목의 데이터가 동일한 컬럼수를 가지기 위해 수행\n",
    "        \"\"\"\n",
    "        imex_cd = [i.split('_')[-1].split('.')[0] for i in self.imexport]\n",
    "\n",
    "        for i in tqdm(range(len(self.pummok))):\n",
    "\n",
    "            cd_number = self.pummok[i].split('_')[1].split('.')[0]\n",
    "            print(cd_number)\n",
    "            file_name = 'imexport_' + self.pummok[i].split('pummok_')[1]\n",
    "            print(file_name)\n",
    "\n",
    "\n",
    "            if cd_number in imex_cd:\n",
    "                test4 = pd.read_csv(self.imexport[imex_cd.index(cd_number)])\n",
    "\n",
    "                new_exim1 = []\n",
    "                new_exim2 = []\n",
    "                new_exim3 = []\n",
    "                new_exim4 = []\n",
    "                new_exim5 = []\n",
    "            \n",
    "                for j in globals()[f'df_{cd_number.split(\"_\")[-1]}']['datadate']:\n",
    "                    target = j//100\n",
    "\n",
    "                    try:\n",
    "                        number = list(test4['datadate']).index(target)\n",
    "\n",
    "\n",
    "                        new_exim1.append(test4['수출(중량)'].iloc[number])\n",
    "                        new_exim2.append(test4['수출(금액)'].iloc[number])\n",
    "                        new_exim3.append(test4['수입(중량)'].iloc[number])\n",
    "                        new_exim4.append(test4['수입(금액)'].iloc[number])\n",
    "                        new_exim5.append(test4['무역수지'].iloc[number])\n",
    "                    except:\n",
    "                        new_exim1.append(np.nan)\n",
    "                        new_exim2.append(np.nan)\n",
    "                        new_exim3.append(np.nan)\n",
    "                        new_exim4.append(np.nan)\n",
    "                        new_exim5.append(np.nan)\n",
    "\n",
    "                df2 = pd.DataFrame()\n",
    "                df2['수출(중량)'] = new_exim1\n",
    "                df2['수출(금액)'] = new_exim2\n",
    "                df2['수입(중량)'] = new_exim3\n",
    "                df2['수입(금액)'] = new_exim4\n",
    "                df2['무역수지'] = new_exim5\n",
    "\n",
    "                globals()[f'df_{cd_number.split(\"_\")[-1]}'] = pd.concat([globals()[f'df_{cd_number.split(\"_\")[-1]}'], df2],axis=1)\n",
    "\n",
    "            else:\n",
    "                df2 = pd.DataFrame()\n",
    "                df2['수출(중량)'] = np.nan\n",
    "                df2['수출(금액)'] = np.nan\n",
    "                df2['수입(중량)'] = np.nan\n",
    "                df2['수입(금액)'] = np.nan\n",
    "                df2['무역수지'] = np.nan\n",
    "\n",
    "                globals()[f'df_{cd_number}'] = pd.concat([globals()[f'df_{cd_number}'], df2], axis=1)\n",
    "            \n",
    "            if check != 0:\n",
    "                if os.path.exists(f'../AI/DATA/data') == False:\n",
    "                    os.mkdir(f'../AI/DATA/data')\n",
    "\n",
    "                if os.path.exists(f'../AI/DATA/data/imexport') == False:\n",
    "                    os.mkdir(f'../AI/DATA/data/imexport')\n",
    "\n",
    "                df2.to_csv(f'../AI/DATA/data/imexport/{file_name}', index=False)\n",
    "\n",
    "    def add_weather(self, check=0):\n",
    "\n",
    "        \"\"\"\n",
    "        check = 중간 산출물을 저장하고 싶다면 check 을 0 이외의 숫자로\n",
    "        weather 품목별 주산지 데이터를 가져와 합치는 함수, 일부 품목 주산지 데이터가 없는 것에 대해서는 np.nan 값으로 합쳐줌\n",
    "        \"\"\"\n",
    "        \n",
    "        weather_cd = [i.split('_')[-1].split('.')[0] for i in self.weather]\n",
    "        print(weather_cd)\n",
    "\n",
    "        for i in tqdm(range(len(self.pummok))):\n",
    "            \n",
    "            cd_number = self.pummok[i].split('_')[-1].split('.')[0]\n",
    "            file_name = 'weather_' + self.pummok[i].split('pummok_')[1]\n",
    "\n",
    "            df = pd.DataFrame()\n",
    "\n",
    "            if cd_number in weather_cd:\n",
    "                \n",
    "                weather_df = pd.read_csv(self.weather[weather_cd.index(cd_number)])\n",
    "\n",
    "                new_exim1 = []\n",
    "                new_exim2 = []\n",
    "                new_exim3 = []\n",
    "                new_exim4 = []\n",
    "                new_exim5 = []\n",
    "                new_exim6 = []\n",
    "                new_exim7 = []\n",
    "                new_exim8 = []\n",
    "\n",
    "                for k in globals()[f'df_{cd_number}']['datadate']:\n",
    "                    try:\n",
    "                        number = list(weather_df['datadate']).index(k)\n",
    "\n",
    "                        new_exim1.append(weather_df['평균온도'].iloc[number])\n",
    "                        new_exim2.append(weather_df['최고온도'].iloc[number])\n",
    "                        new_exim3.append(weather_df['최저온도'].iloc[number])\n",
    "                        new_exim4.append(weather_df['평균습도'].iloc[number])\n",
    "                        new_exim5.append(weather_df['최저습도'].iloc[number])\n",
    "                        new_exim6.append(weather_df['강수량'].iloc[number])\n",
    "                        new_exim7.append(weather_df['평균풍속'].iloc[number])\n",
    "                        new_exim8.append(weather_df['일조시간'].iloc[number])\n",
    "                    except:\n",
    "                        new_exim1.append(np.nan)\n",
    "                        new_exim2.append(np.nan)\n",
    "                        new_exim3.append(np.nan)\n",
    "                        new_exim4.append(np.nan)\n",
    "                        new_exim5.append(np.nan)\n",
    "                        new_exim6.append(np.nan)\n",
    "                        new_exim7.append(np.nan)\n",
    "                        new_exim8.append(np.nan)\n",
    "\n",
    "                df[f'평균온도'] = new_exim1\n",
    "                df[f'최고온도'] = new_exim2\n",
    "                df[f'최저온도'] = new_exim3\n",
    "                df[f'평균습도'] = new_exim4\n",
    "                df[f'최저습도'] = new_exim5\n",
    "                df[f'강수량'] = new_exim6\n",
    "                df[f'평균풍속'] = new_exim7\n",
    "                df[f'일조시간'] = new_exim8\n",
    "                \n",
    "\n",
    "            else:\n",
    "                df[f'평균온도'] = np.nan\n",
    "                df[f'최고온도'] = np.nan\n",
    "                df[f'최저온도'] = np.nan\n",
    "                df[f'평균습도'] = np.nan\n",
    "                df[f'최저습도'] = np.nan\n",
    "                df[f'강수량'] = np.nan\n",
    "                df[f'평균풍속'] = np.nan\n",
    "                df[f'일조시간'] = np.nan\n",
    "\n",
    "            globals()[f'df_{cd_number}'] = pd.concat([globals()[f'df_{cd_number}'], df], axis=1)\n",
    "\n",
    "            if check !=0:\n",
    "                if os.path.exists(f'../AI/DATA/data') == False:\n",
    "                    os.mkdir(f'../AI/DATA/data')\n",
    "\n",
    "                if os.path.exists(f'../AI/DATA/data/weather') == False:\n",
    "                    os.mkdir(f'../AI/DATA/data/weather')\n",
    "\n",
    "                df.to_csv(f'../AI/DATA/data/weather/weather_{cd_number}.csv', index=False)\n",
    "\n",
    "    \n",
    "    def add_categorical(self, out_dir, data_type=\"train\", check=0):\n",
    "        \"\"\"\n",
    "        check = 중간 산출물을 저장하고 싶다면 check 을 0 이외의 숫자로\n",
    "        일자별 정보를 넣어주는 함수, 월별, 상순, 하순, 중순 을 원핫 인코딩을 통해 데이터로 넣어주는 함수\n",
    "        모델이 각 행마다의 정보에서 몇월인지 상순인지 하순인지 파악하며 훈련시키기 위한 변수\n",
    "        \"\"\"\n",
    "        for i in tqdm(self.pummok):\n",
    "            name = i.split('_')[-1].split('.')[0]\n",
    "\n",
    "            day_set = []\n",
    "            month_set = []\n",
    "\n",
    "            for k in globals()[f'df_{name}']['datadate']:\n",
    "                day = k % 100\n",
    "                month = k % 10000 // 100\n",
    "\n",
    "                if day <= 10:\n",
    "                    day_set.append('초순')\n",
    "                elif (day > 10) and (day <= 20):\n",
    "                    day_set.append('중순')\n",
    "                else:\n",
    "                    day_set.append('하순')\n",
    "\n",
    "                month_set.append(f'{month}월')\n",
    "\n",
    "            globals()[f'df_{name}']['일자구분'] = day_set\n",
    "            globals()[f'df_{name}']['월구분'] = month_set\n",
    "\n",
    "            globals()[f'df_{name}'] = pd.get_dummies(globals()[f'df_{name}'], columns=['일자구분', '월구분'])\n",
    "\n",
    "            if check !=0:\n",
    "                if os.path.exists(f'../AI/DATA/data') == False:\n",
    "                    os.mkdir(f'../AI/DATA/data')\n",
    "\n",
    "                if data_type != \"train\":\n",
    "                    if os.path.exists(f'../AI/DATA/data/{data_type}') == False:\n",
    "                        os.mkdir(\"../AI/DATA/data/{data_type}\")\n",
    "                    if os.path.exists(f'../AI/DATA/data/{data_type}/{out_dir}') == False:\n",
    "                        os.mkdir(f'../AI/DATA/data/{data_type}/{out_dir}')\n",
    "                    globals()[f'df_{name}'].to_csv(f'../AI/DATA/data/{data_type}/{out_dir}/{data_type}_{name}.csv', index=False)\n",
    "                else:\n",
    "                    if os.path.exists(f'../AI/DATA/data/{out_dir}') == False:\n",
    "                        os.mkdir(f'../AI/DATA/data/{out_dir}')\n",
    "                    globals()[f'df_{name}'].to_csv(f'../AI/DATA/data/{out_dir}/{data_type}_{name}.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessing_data('DATA/raw/*.csv')\n",
    "data.add_pummock(check=1)\n",
    "data.add_dosomae(check=1)\n",
    "data.add_dosomae(option=2, check=1)\n",
    "data.add_imexport(check=1)\n",
    "data.add_weather(check=1)\n",
    "data.add_categorical('train', data_type=\"train\" ,check=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 전처리 및 저장 (중간저장 X, 최종저장 O) - train\n",
    "# data = preprocessing_data('./aT_train_raw/*.csv')\n",
    "# data.add_pummock()\n",
    "# data.add_dosomae()\n",
    "# data.add_dosomae(option=2)\n",
    "# data.add_imexport()\n",
    "# data.add_weather()\n",
    "# data.add_categorical('train', data_type=\"train\" ,check=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessing_data('DATA/raw/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.add_pummock(check=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dome_1.csv\n",
      "dome_25.csv\n",
      "dome_29.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data.add_dosomae(check=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some_29.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some_25.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.99it/s]\n"
     ]
    }
   ],
   "source": [
    "data.add_dosomae(option=2, check=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 38.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "imexport_29.csv\n",
      "25\n",
      "imexport_25.csv\n",
      "1\n",
      "imexport_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data.add_imexport(check=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['29', '28', '1', '24']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  4.88it/s]\n"
     ]
    }
   ],
   "source": [
    "data.add_weather(check=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 32.44it/s]\n"
     ]
    }
   ],
   "source": [
    "data.add_categorical('train', data_type=\"train\" ,check=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
